{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "from os.path import join\n",
    "from os import listdir\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = '/home/selp/Documents/AU/Speech/VCTK-Corpus/wav48'\n",
    "for path in [join(pt, f) for f in listdir(pt)]:\n",
    "    with open(join(path,'wav.scp'),'w+') as file:\n",
    "        for f in sorted(listdir(path)):\n",
    "            if f[0] == 'p':\n",
    "                file.write('{} {}\\n'.format(f, join(path, f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "pt = '/home/selp/Documents/AU/Speech/VCTK-Corpus/wav48'\n",
    "for path in [join(pt, f) for f in sorted(listdir(pt))]:\n",
    "    os.system('{} --config={} scp:{} ark:{}'.format('/home/selp/Documents/kaldi/src/featbin/compute-mfcc-feats',\n",
    "        '/home/selp/Documents/AU/Speech/mfcc.conf', join(path, 'wav.scp'), join(path, 'mfcc.ark')))\n",
    "    os.system('{} --delta-order=2 ark:{} ark:{}'.format('/home/selp/Documents/kaldi/src/featbin/add-deltas',\n",
    "        join(path, 'mfcc.ark'), join(path, 'mfcc_delta.ark')))\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import kaldi_io\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "keys_lists = list()\n",
    "keys_lists_noisy = list()\n",
    "data = list()\n",
    "data_noisy = list()\n",
    "pt = '/home/selp/Documents/AU/Speech/VCTK-Corpus/wav48'\n",
    "for path in [join(pt, f) for f in sorted(listdir(pt))]:\n",
    "    global_id = 0\n",
    "    keys_list = list()\n",
    "    keys_list.append(global_id)\n",
    "    if path[-1] == 'y':\n",
    "        data_noisy.append(np.array([]))\n",
    "    else:\n",
    "        data.append(np.array([]))\n",
    "    for key,mat in kaldi_io.read_mat_ark(join(path, 'mfcc_delta.ark')):\n",
    "        if path[-1] == 'y':\n",
    "            if data_noisy[-1].shape[0] == 0:\n",
    "                data_noisy[-1] = mat\n",
    "            else:\n",
    "                data_noisy[-1] = np.append(data_noisy[-1], mat, axis=0)\n",
    "        else:\n",
    "            if data[-1].shape[0] == 0:\n",
    "                data[-1] = mat\n",
    "            else:\n",
    "                data[-1] = np.append(data[-1], mat, axis=0)\n",
    "        global_id += mat.shape[0]\n",
    "        keys_list.append(global_id)\n",
    "    if path[-1] == 'y':\n",
    "        keys_lists_noisy.append(np.array(keys_list))\n",
    "    else:\n",
    "        keys_lists.append(np.array(keys_list))\n",
    "    print(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_speakers_data(data, keys_lists):\n",
    "    data_speakers = list()\n",
    "    data_speakers_test = list()\n",
    "    for i in range(len(data)):\n",
    "        if i != 108:\n",
    "            keys = keys_lists[i]\n",
    "            dat = data[i]\n",
    "            for j in range(len(keys)-1):\n",
    "                cls = i\n",
    "                if i >= 108:\n",
    "                    cls = i - 1\n",
    "                y = np.zeros(len(data) - 1)\n",
    "                y[cls] = 1\n",
    "                if j < ((len(keys)-1)*4//5):\n",
    "                    data_speakers.append((dat[keys[j]:keys[j+1]], y))\n",
    "                else:\n",
    "                    data_speakers_test.append((dat[keys[j]:keys[j+1]], y))\n",
    "    return data_speakers, data_speakers_test        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(data_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train tracks:  35113 \n",
      " test tracks:  8837\n"
     ]
    }
   ],
   "source": [
    "print(\"train tracks: \", len(data_speakers), \"\\n test tracks: \", len(data_speakers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.layer1 = nn.Linear(39, 30)\n",
    "        self.layer2 = nn.Linear(30, 21)#30,21\n",
    "        self.layer3 = nn.Linear(21, 14)#21,14\n",
    "        self.layer4 = nn.Linear(14, 21)#14,21\n",
    "        self.layer5 = nn.Linear(21, 30)#21,30\n",
    "        self.layer6 = nn.Linear(30, 39)\n",
    "    def forward(self, input_data):\n",
    "        x = F.relu(self.layer1(input_data))\n",
    "        x = F.relu(self.layer2(x))#dr_o(0.1)\n",
    "        x = F.relu(self.layer3(x))\n",
    "        x = F.relu(self.layer4(x))#dr_o(0.1)\n",
    "        x = F.relu(self.layer5(x))\n",
    "        x = self.layer6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = np.copy(data[0][:data[0].shape[0]*4//5])\n",
    "data_noisy_full = np.copy(data_noisy[0][:data_noisy[0].shape[0]*4//5])\n",
    "data_full_test = np.copy(data[0][data[0].shape[0]*4//5:])\n",
    "data_noisy_full_test = np.copy(data_noisy[0][data_noisy[0].shape[0]*4//5:])\n",
    "for i in range(1, len(data)):\n",
    "    if i != 108:\n",
    "        data_full = np.append(data_full, data[i][:data[i].shape[0]*4//5], axis=0)\n",
    "        data_full_test = np.append(data_full_test, data[i][data[i].shape[0]*4//5:], axis=0)\n",
    "        data_noisy_full = np.append(data_noisy_full, data_noisy[i][:data_noisy[i].shape[0]*4//5], axis=0)\n",
    "        data_noisy_full_test = np.append(data_noisy_full_test, data_noisy[i][data_noisy[i].shape[0]*4//5:], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500841, 39)\n",
      "(12500841, 39)\n",
      "(3125262, 39)\n",
      "(3125262, 39)\n"
     ]
    }
   ],
   "source": [
    "print(data_full.shape)\n",
    "print(data_noisy_full.shape)\n",
    "print(data_full_test.shape)\n",
    "print(data_noisy_full_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_noisy = DataLoader(torch.tensor(data_noisy_full), batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeMod = AutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch_num, learning_rate, batch_size, dl_noisy, dl_ob, logging=False, writer=None):\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    global step\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        for i, X in enumerate(dl_noisy):\n",
    "            y = dl_ob[batch_size*i: batch_size*(i + 1)]\n",
    "\n",
    "            model.zero_grad()\n",
    "            res = model(X)\n",
    "            loss = loss_function(res, torch.FloatTensor(y))\n",
    "        \n",
    "            if logging:\n",
    "                writer.add_scalar('loss_train/loss', loss, step)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            step += 1\n",
    "        print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoEncoder()\n",
    "# checkpoint = torch.load('checkpoint_autoencoder.pth.tar')\n",
    "# start_epoch = checkpoint['epoch']\n",
    "# model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "writer = SummaryWriter(log_dir=join('save_root', 'loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "CPU times: user 21min 2s, sys: 3.08 s, total: 21min 5s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(aeMod, 2, 0.00001, 1024, dl_noisy, data_full, True, writer)#4 epoches\n",
    "train(aeMod, 2, 0.00005, 1024, dl_noisy, data_full, True, writer)#4 epoches\n",
    "train(aeMod, 2, 0.00015, 1024, dl_noisy, data_full, True, writer)#2\n",
    "train(aeMod, 2, 0.0005, 1024, dl_noisy, data_full, True, writer)#4\n",
    "train(aeMod, 2, 0.001, 1024, dl_noisy, data_full, True, writer)#2\n",
    "train(aeMod, 1, 0.0005, 1024, dl_noisy, data_full, True, writer)#1\n",
    "train(aeMod, 1, 0.0002, 1024, dl_noisy, data_full, True, writer)#1\n",
    "train(aeMod, 1, 0.0005, 1024, dl_noisy, data_full, True, writer)#1\n",
    "##time on 2 epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'epoch': 19,\n",
    "    'state_dict': aeMod.state_dict()\n",
    "}, 'checkpoint_autoencoder.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(124.7916)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.MSELoss()(torch.FloatTensor(data_noisy_full), torch.FloatTensor(data_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.MSELoss()(aeMod(torch.FloatTensor(data_noisy_full)), torch.FloatTensor(data_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min:58\n",
      " max:1926\n"
     ]
    }
   ],
   "source": [
    "min_sections = 500\n",
    "max_sections = 200\n",
    "for keys in keys_lists:\n",
    "    arr = keys[1:] - keys[:-1]\n",
    "    min_v = np.min(arr)\n",
    "    max_v = np.max(arr)\n",
    "    if min_v < min_sections:\n",
    "        min_sections = min_v\n",
    "    if max_v > max_sections:\n",
    "        max_sections = max_v\n",
    "print(\"min:{}\\n max:{}\".format(min_sections, max_sections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "    (139202, 39)\n",
      "    (139725, 39)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    if data[i].shape != data_noisy[i].shape:\n",
    "        print(i)\n",
    "        print(\"    {}\".format(data[i].shape))\n",
    "        print(\"    {}\".format(data_noisy[i].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, features_num, hidden_dim, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(features_num, hidden_dim)\n",
    "        \n",
    "        self.linear1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear3 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        _, (lstm_out, _) = self.lstm(input_data)\n",
    "        \n",
    "        x = F.relu(self.linear1(lstm_out))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = torch.nn.Softmax(dim=2)(self.linear3(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_batched, data_y, learning_rate = 0.01, epoches=1, logging=False, writer=None, log_name='loss', classifier=classifier):\n",
    "    global step\n",
    "    loss_fun = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "    for epoch in range(epoches):\n",
    "        for it in range(len(data_batched)):\n",
    "            X, y = data_batched[it], data_y[it]\n",
    "            classifier.zero_grad()\n",
    "            res = classifier(X)\n",
    "            loss = loss_fun(res, torch.FloatTensor(y.reshape(1, -1, 108)))\n",
    "            if logging:\n",
    "                writer.add_scalar('loss_train/' + log_name, loss, step)\n",
    "            step += 1\n",
    "            it += 1\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "writer = SummaryWriter(log_dir=join('save_root', 'loss_classifier_clear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LSTMClassifier(39, 128, len(data) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batched, data_y = prepare_data(data_speakers, 256)\n",
    "data_batched_test, data_y_test = prepare_data(data_speakers_test, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(data_batched, data_y, 0.01, 2, True, writer)\n",
    "train(data_batched, data_y, 0.005, 1, True, writer)\n",
    "train(data_batched, data_y, 0.002, 1, True, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 3s, sys: 6.53 s, total: 13min 10s\n",
      "Wall time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(data_batched, data_y, 0.0008, 1, True, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7344121308136246\n"
     ]
    }
   ],
   "source": [
    "#accuracy with classifier trained on clear data for 5 epoches\n",
    "print(accuracy_classifier(data_batched_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'epoch': 3,\n",
    "    'state_dict': classifier.state_dict(),\n",
    "}, 'checkpoint_clsssifier_on_clear_data.pth.tar')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_autoencoded = list()\n",
    "for d in data_noisy:\n",
    "    data_autoencoded.append(aeMod(torch.FloatTensor(d)).detach().numpy().reshape(-1, 39))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_speakers_train, ae_speakers_test = prepare_speakers_data(data_autoencoded, keys_lists_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(ae_speakers_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_data_batched, ae_data_y = prepare_data(ae_speakers_train, 256)\n",
    "ae_data_batched_test, ae_data_y_test = prepare_data(ae_speakers_test, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "writer = SummaryWriter(log_dir=join('save_root', 'loss_classifier_ae'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LSTMClassifier(39, 128, len(data) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 1min 36s, sys: 32.1 s, total: 1h 2min 8s\n",
      "Wall time: 10min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(ae_data_batched, ae_data_y, 0.01, 2, True, writer)\n",
    "train(ae_data_batched, ae_data_y, 0.005, 1, True, writer)\n",
    "train(ae_data_batched, ae_data_y, 0.002, 1, True, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 8s, sys: 5.44 s, total: 14min 14s\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(ae_data_batched, ae_data_y, 0.0008, 3, True, writer)\n",
    "##time for 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoencoded test data accuracy:  0.553807853343895\n",
      "clear test data accuracy:  0.05216702500848704\n"
     ]
    }
   ],
   "source": [
    "#accuracy with classifier trained on cleaned by autoencoder data for 7 epoches\n",
    "print(\"autoencoded test data accuracy: \", accuracy_classifier(ae_data_batched_test))\n",
    "print(\"clear test data accuracy: \", accuracy_classifier(data_batched_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'epoch': 7,\n",
    "    'state_dict': classifier.state_dict(),\n",
    "}, 'checkpoint_clsssifier_on_ae_data.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_13 = LSTMClassifier(13, 128, len(data) - 1)\n",
    "step = 1\n",
    "writer = SummaryWriter(log_dir=join('save_root', 'loss_mfcc_13'))\n",
    "data_batched_13, data_y_13 = prepare_data(data_speakers, 256, 0, 13)\n",
    "data_batched_test_13, data_y_test_13 = prepare_data(data_speakers_test, 256, 0, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(data_batched_13, data_y_13, 0.01, 2, True, writer, log_name='loss_mfcc_13', classifier=classifier_13)\n",
    "train(data_batched_13, data_y_13, 0.005, 1, True, writer, log_name='loss_mfcc_13', classifier=classifier_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6520312323186602\n"
     ]
    }
   ],
   "source": [
    "#accuracy with classifier trained on mfcc features (13) for 3 epoches\n",
    "print(accuracy_classifier(data_batched_test_13, classifier=classifier_13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_13 = LSTMClassifier(13, 128, len(data) - 1)\n",
    "step = 1\n",
    "writer = SummaryWriter(log_dir=join('save_root', 'loss_mfcc_deltas_1'))\n",
    "data_batched_13, data_y_13 = prepare_data(data_speakers, 256, 13, 26)\n",
    "data_batched_test_13, data_y_test_13 = prepare_data(data_speakers_test, 256, 13, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55min 51s, sys: 17.8 s, total: 56min 9s\n",
      "Wall time: 9min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(data_batched_13, data_y_13, 0.01, 2, True, writer, log_name='loss_mfcc_deltas_1', classifier=classifier_13)\n",
    "train(data_batched_13, data_y_13, 0.005, 1, True, writer, log_name='loss_mfcc_deltas_1', classifier=classifier_13)\n",
    "##a little bit corrupted loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08464410999207876\n"
     ]
    }
   ],
   "source": [
    "#accuracy with classifier trained on mfcc delatas_1 (13) for 3 epoches\n",
    "print(accuracy_classifier(data_batched_test_13, classifier=classifier_13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_13 = LSTMClassifier(13, 128, len(data) - 1)\n",
    "step = 1\n",
    "writer = SummaryWriter(log_dir=join('save_root', 'loss_mfcc_deltas_2'))\n",
    "data_batched_13, data_y_13 = prepare_data(data_speakers, 256, 26, 39)\n",
    "data_batched_test_13, data_y_test_13 = prepare_data(data_speakers_test, 256, 26, 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 2min 17s, sys: 18 s, total: 1h 2min 35s\n",
      "Wall time: 10min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(data_batched_13, data_y_13, 0.01, 2, True, writer, log_name='loss_mfcc_deltas_2', classifier=classifier_13)\n",
    "train(data_batched_13, data_y_13, 0.005, 1, True, writer, log_name='loss_mfcc_deltas_2', classifier=classifier_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04899852891252687\n"
     ]
    }
   ],
   "source": [
    "#accuracy with classifier trained on mfcc delatas_2 (13) for 3 epoches\n",
    "print(accuracy_classifier(data_batched_test_13, classifier=classifier_13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_classifier(data_batches_test, classifier=classifier):\n",
    "    true_val = 0\n",
    "\n",
    "    for it in range(len(data_batches_test)):\n",
    "        X, y = data_batches_test[it], data_y_test[it]\n",
    "        res = classifier(X)\n",
    "        true_val += np.sum(np.argmax(res.detach().numpy().reshape(-1, 108), axis=1) == np.argmax(y, axis=1))\n",
    "    return true_val/len(data_speakers_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(shuffled_data, batch_size, begin=0, end=39):\n",
    "    data_batched = list()\n",
    "    data_y = list()\n",
    "    for i in range(math.ceil(len(shuffled_data)/batch_size)):\n",
    "        batch_lens = list()#np.zeros((batch_size,))\n",
    "        for x, _ in shuffled_data[batch_size*i: batch_size*(i + 1)]:\n",
    "            batch_lens.append(x.shape[0])\n",
    "        batch_lengths = np.array(batch_lens)\n",
    "        max_len = np.max(batch_lens)\n",
    "        batch = np.zeros((max_len, batch_lengths.shape[0], end - begin))\n",
    "        dt_y = np.zeros((batch_lengths.shape[0], 108))\n",
    "        j = 0\n",
    "        for x, y in shuffled_data[batch_size*i: batch_size*(i + 1)]:\n",
    "            batch[0:batch_lengths[j], j] = x[:, begin:end]\n",
    "            dt_y[j] = y\n",
    "            j += 1\n",
    "        args = np.argsort(-batch_lengths)\n",
    "        data_batched.append(torch.nn.utils.rnn.pack_padded_sequence(torch.FloatTensor(batch[:,args,:]), batch_lengths[args]))\n",
    "        data_y.append(dt_y[args])\n",
    "    return data_batched, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
